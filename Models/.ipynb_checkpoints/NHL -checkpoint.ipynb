{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV containing player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>PTS</th>\n",
       "      <th>+/-</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>SHFT</th>\n",
       "      <th>SHFT/G</th>\n",
       "      <th>PROD</th>\n",
       "      <th>POS</th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>TIMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Suter Ryan</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>-8</td>\n",
       "      <td>26:42:00</td>\n",
       "      <td>2222</td>\n",
       "      <td>27.1</td>\n",
       "      <td>46:34:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Doughty Drew</td>\n",
       "      <td>LA</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-34</td>\n",
       "      <td>26:36:00</td>\n",
       "      <td>2393</td>\n",
       "      <td>29.2</td>\n",
       "      <td>48:27:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Letang Kris</td>\n",
       "      <td>PIT</td>\n",
       "      <td>65.0</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>25:58:00</td>\n",
       "      <td>1923</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30:07:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jones Seth</td>\n",
       "      <td>CBJ</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>25:49:00</td>\n",
       "      <td>2214</td>\n",
       "      <td>29.5</td>\n",
       "      <td>42:06:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Josi Roman</td>\n",
       "      <td>NSH</td>\n",
       "      <td>82.0</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>25:10:00</td>\n",
       "      <td>2359</td>\n",
       "      <td>28.8</td>\n",
       "      <td>36:51:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        PLAYER TEAM    GP   G   A  PTS  +/-     TOI/G  SHFT  \\\n",
       "0           0    Suter Ryan  MIN  82.0   7  40   47   -8  26:42:00  2222   \n",
       "1           1  Doughty Drew   LA  82.0   8  37   45  -34  26:36:00  2393   \n",
       "2           2   Letang Kris  PIT  65.0  16  40   56   13  25:58:00  1923   \n",
       "3           3    Jones Seth  CBJ  75.0   9  37   46    1  25:49:00  2214   \n",
       "4           4    Josi Roman  NSH  82.0  15  41   56    9  25:10:00  2359   \n",
       "\n",
       "   SHFT/G      PROD POS    hr   min  sec   TIMES  \n",
       "0    27.1  46:34:00   D  26.0  42.0  0.0  2132.0  \n",
       "1    29.2  48:27:00   D  26.0  36.0  0.0  2132.0  \n",
       "2    29.6  30:07:00   D  25.0  58.0  0.0  1625.0  \n",
       "3    29.5  42:06:00   D  25.0  49.0  0.0  1875.0  \n",
       "4    28.8  36:51:00   D  25.0  10.0  0.0  2050.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOI_df = pd.read_csv('Final-DataFrames/NHLTotTime.csv')\n",
    "TOI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert \"Time On Ice per Game\" column to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>PTS</th>\n",
       "      <th>+/-</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>SHFT</th>\n",
       "      <th>SHFT/G</th>\n",
       "      <th>PROD</th>\n",
       "      <th>POS</th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>TIMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Suter Ryan</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>-8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2222</td>\n",
       "      <td>27.1</td>\n",
       "      <td>46:34:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Doughty Drew</td>\n",
       "      <td>LA</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-34</td>\n",
       "      <td>26.6</td>\n",
       "      <td>2393</td>\n",
       "      <td>29.2</td>\n",
       "      <td>48:27:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        PLAYER TEAM    GP  G   A  PTS  +/- TOI/G  SHFT  SHFT/G  \\\n",
       "0           0    Suter Ryan  MIN  82.0  7  40   47   -8  26.7  2222    27.1   \n",
       "1           1  Doughty Drew   LA  82.0  8  37   45  -34  26.6  2393    29.2   \n",
       "\n",
       "       PROD POS    hr   min  sec   TIMES  \n",
       "0  46:34:00   D  26.0  42.0  0.0  2132.0  \n",
       "1  48:27:00   D  26.0  36.0  0.0  2132.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the times in the \"TOI/G\" column\n",
    "timelist = list(TOI_df['TOI/G'])\n",
    "\n",
    "for i in range(len(TOI_df['TOI/G'])):\n",
    "    timesplit = timelist[i].split(':')\n",
    "    \n",
    "    \n",
    "    whole = int(timesplit[0])\n",
    "    decimal = int(timesplit[1])/60\n",
    "    \n",
    "    minutes = whole + decimal\n",
    "    \n",
    "    TOI_df['TOI/G'][i] = minutes\n",
    "    \n",
    "TOI_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new DataFrame with important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHL_stats = TOI_df[['PLAYER', 'GP', 'TOI/G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read our CSV containing Bio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Injury Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32</td>\n",
       "      <td>Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25</td>\n",
       "      <td>Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21</td>\n",
       "      <td>Not Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27</td>\n",
       "      <td>Not Injured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 POSITION  HEIGHT  WEIGHT             PLAYER  AGE Injury Status\n",
       "0           0       LW    74.0     214  Abdelkader Justin   32       Injured\n",
       "1           1       LW    71.0     196       Aberg Pontus   25       Injured\n",
       "2           2       RW    69.0     171     Abramov Vitaly   21   Not Injured\n",
       "3           3        C    70.0     205       Acciari Noel   27   Not Injured"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Final-DataFrames/NHLModel.csv').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHL_1 = pd.read_csv('Final-DataFrames/NHLModel.csv')\n",
    "\n",
    "\n",
    "# Select columns of interest\n",
    "NHL_select = NHL_1[['POSITION', 'HEIGHT', 'WEIGHT', 'PLAYER', 'AGE', 'Injury Status']]\n",
    "\n",
    "#Merge Playerr Bio data with the player stat data \n",
    "NHL = NHL_select.merge(NHL_stats, how='right', on='PLAYER')\n",
    "\n",
    "#Drop NA rows\n",
    "NHL = NHL.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BMI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Injury Status</th>\n",
       "      <th>GP</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Injured</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>27.472973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Injured</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>27.333466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.8667</td>\n",
       "      <td>25.249527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.9833</td>\n",
       "      <td>29.411224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LW</td>\n",
       "      <td>72.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>Agostino Kenny</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.9167</td>\n",
       "      <td>26.986304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POSITION  HEIGHT  WEIGHT             PLAYER   AGE Injury Status    GP  \\\n",
       "0       LW    74.0   214.0  Abdelkader Justin  32.0       Injured  71.0   \n",
       "1       LW    71.0   196.0       Aberg Pontus  25.0       Injured  59.0   \n",
       "2       RW    69.0   171.0     Abramov Vitaly  21.0   Not Injured   1.0   \n",
       "3        C    70.0   205.0       Acciari Noel  27.0   Not Injured  72.0   \n",
       "4       LW    72.0   199.0     Agostino Kenny  27.0   Not Injured  63.0   \n",
       "\n",
       "     TOI/G        BMI  \n",
       "0     15.4  27.472973  \n",
       "1     14.6  27.333466  \n",
       "2  13.8667  25.249527  \n",
       "3  12.9833  29.411224  \n",
       "4  12.9167  26.986304  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NHL['BMI'] = (NHL['WEIGHT'] / (NHL['HEIGHT'] ** 2)) * 703\n",
    "NHL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot Encode The NHL dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GP</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Injury Status_Injured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>27.472973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>27.333466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.8667</td>\n",
       "      <td>25.249527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.9833</td>\n",
       "      <td>29.411224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LW</td>\n",
       "      <td>72.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>Agostino Kenny</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.9167</td>\n",
       "      <td>26.986304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POSITION  HEIGHT  WEIGHT             PLAYER   AGE    GP    TOI/G        BMI  \\\n",
       "0       LW    74.0   214.0  Abdelkader Justin  32.0  71.0     15.4  27.472973   \n",
       "1       LW    71.0   196.0       Aberg Pontus  25.0  59.0     14.6  27.333466   \n",
       "2       RW    69.0   171.0     Abramov Vitaly  21.0   1.0  13.8667  25.249527   \n",
       "3        C    70.0   205.0       Acciari Noel  27.0  72.0  12.9833  29.411224   \n",
       "4       LW    72.0   199.0     Agostino Kenny  27.0  63.0  12.9167  26.986304   \n",
       "\n",
       "   Injury Status_Injured  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 = injured\n",
    "# 0 = not injured\n",
    "Encoded_df = pd.get_dummies(NHL, columns=['Injury Status'])[['POSITION', 'HEIGHT', 'WEIGHT', 'PLAYER', 'AGE', 'GP', 'TOI/G','BMI', 'Injury Status_Injured']]\n",
    "Encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set y values equal to our Injury Status_Injured column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(Encoded_df['Injury Status_Injured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = pd.get_dummies(Encoded_df[['POSITION', 'HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']], columns=['POSITION'])\n",
    "X = Encoded_df[['HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']]\n",
    "\n",
    "New_X = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(New_X, y, train_size=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([X_test[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5920852359208524\n",
      "Testing Data Score: 0.6027397260273972\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a StandardScater model and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train.reshape(-1, 1))\n",
    "# X_scaler = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform the training and testing data using the X_scaler and y_scaler models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.703\n",
      "k: 3, Train/Test Score: 0.854/0.753\n",
      "k: 5, Train/Test Score: 0.817/0.753\n",
      "k: 7, Train/Test Score: 0.808/0.763\n",
      "k: 9, Train/Test Score: 0.795/0.772\n",
      "k: 11, Train/Test Score: 0.785/0.781\n",
      "k: 13, Train/Test Score: 0.787/0.767\n",
      "k: 15, Train/Test Score: 0.776/0.776\n",
      "k: 17, Train/Test Score: 0.770/0.767\n",
      "k: 19, Train/Test Score: 0.776/0.753\n",
      "k: 21, Train/Test Score: 0.773/0.763\n",
      "k: 23, Train/Test Score: 0.770/0.749\n",
      "k: 25, Train/Test Score: 0.766/0.763\n",
      "k: 27, Train/Test Score: 0.767/0.758\n",
      "k: 29, Train/Test Score: 0.767/0.758\n",
      "k: 31, Train/Test Score: 0.772/0.753\n",
      "k: 33, Train/Test Score: 0.756/0.763\n",
      "k: 35, Train/Test Score: 0.753/0.772\n",
      "k: 37, Train/Test Score: 0.747/0.758\n",
      "k: 39, Train/Test Score: 0.741/0.753\n",
      "k: 41, Train/Test Score: 0.746/0.753\n",
      "k: 43, Train/Test Score: 0.743/0.749\n",
      "k: 45, Train/Test Score: 0.741/0.744\n",
      "k: 47, Train/Test Score: 0.743/0.744\n",
      "k: 49, Train/Test Score: 0.746/0.735\n",
      "k: 51, Train/Test Score: 0.741/0.740\n",
      "k: 53, Train/Test Score: 0.741/0.731\n",
      "k: 55, Train/Test Score: 0.744/0.735\n",
      "k: 57, Train/Test Score: 0.746/0.735\n",
      "k: 59, Train/Test Score: 0.741/0.740\n",
      "k: 61, Train/Test Score: 0.737/0.721\n",
      "k: 63, Train/Test Score: 0.741/0.735\n",
      "k: 65, Train/Test Score: 0.735/0.735\n",
      "k: 67, Train/Test Score: 0.737/0.731\n",
      "k: 69, Train/Test Score: 0.740/0.731\n",
      "k: 71, Train/Test Score: 0.737/0.726\n",
      "k: 73, Train/Test Score: 0.743/0.726\n",
      "k: 75, Train/Test Score: 0.741/0.731\n",
      "k: 77, Train/Test Score: 0.741/0.731\n",
      "k: 79, Train/Test Score: 0.737/0.735\n",
      "k: 81, Train/Test Score: 0.734/0.740\n",
      "k: 83, Train/Test Score: 0.735/0.731\n",
      "k: 85, Train/Test Score: 0.737/0.735\n",
      "k: 87, Train/Test Score: 0.729/0.740\n",
      "k: 89, Train/Test Score: 0.738/0.735\n",
      "k: 91, Train/Test Score: 0.731/0.731\n",
      "k: 93, Train/Test Score: 0.726/0.753\n",
      "k: 95, Train/Test Score: 0.728/0.749\n",
      "k: 97, Train/Test Score: 0.729/0.753\n",
      "k: 99, Train/Test Score: 0.728/0.753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 100, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 100, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 100, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 25, Train/Test Score: 0.766/0.763\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "k = int( math.sqrt(len(X_train)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "train_score = knn.score(X_train_scaled, y_train)\n",
    "test_score = knn.score(X_test_scaled, y_test)\n",
    "train_scores.append(train_score)\n",
    "test_scores.append(test_score)\n",
    "print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions Based On X_Test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113,   0],\n",
       "       [106,   0]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5159817351598174"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The K value of 37 has the best accuracy score of : 0.7031963470319634\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "accuracy_list = []\n",
    "\n",
    "for k in range(1, 400, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    accuracy_dict[accuracy_score(y_test, y_pred)] = k\n",
    "    \n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    best_k = accuracy_dict[max(accuracy_list)]\n",
    "    \n",
    "print(f' The K value of {accuracy_dict[max(accuracy_list)]} has the best accuracy score of : {max(accuracy_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Accurate K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95, 18],\n",
       "       [47, 59]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= best_k)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "        \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ulyss\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make random forest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict injury or no injury using clf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "#Here we run on the test set\n",
    "preds=clf.predict(X_test)\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print summary information from running prediction on X_test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted as injured:\n",
      "(103, 7)\n",
      "Predicted as not injured\n",
      "(116, 7)\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.DataFrame(X_test)\n",
    "newdf['predicted']=preds\n",
    "#print(newdf['predicted'].value_counts)\n",
    "#newdf.index\n",
    "#newdf.head()\n",
    "odf=Encoded_df.loc[newdf.index]\n",
    "odf['predicted']=preds\n",
    "print(\"Predicted as injured:\")\n",
    "print(newdf.loc[newdf.predicted==1].shape)\n",
    "print(\"Predicted as not injured\")\n",
    "print(newdf.loc[newdf.predicted==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9863013698630136\n",
      "Testing Data Score: 0.7853881278538812\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5251\n"
     ]
    }
   ],
   "source": [
    "# Assess quality of preditor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(odf['Injury Status_Injured'], odf['predicted']) \n",
    "print(\"MSE: %.4f\"%mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Our Model Functions From Our Python File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import train_test, logistic_model, knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Variables Based On The DataFrame and Columns of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']\n",
    "X_tn, X_tt, y_tn, y_tt = train_test(Encoded_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6453576864535768\n",
      "Testing Data Score: 0.5570776255707762\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.60882800608828\n",
      "Testing Data Score: 0.5799086757990868\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6057838660578386\n",
      "Testing Data Score: 0.589041095890411\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6149162861491628\n",
      "Testing Data Score: 0.6164383561643836\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0\n",
      " 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6149162861491628\n",
      "Testing Data Score: 0.5707762557077626\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1\n",
      " 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1\n",
      " 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.593607305936073\n",
      "Testing Data Score: 0.6575342465753424\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1\n",
      " 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6270928462709284\n",
      "Testing Data Score: 0.5616438356164384\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.619482496194825\n",
      "Testing Data Score: 0.5616438356164384\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1\n",
      " 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0\n",
      " 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6210045662100456\n",
      "Testing Data Score: 0.5616438356164384\n"
     ]
    }
   ],
   "source": [
    "trn_scores = []\n",
    "tst_scores = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    X_tn, X_tt, y_tn, y_tt = train_test(Encoded_df, columns)\n",
    "    trn, tst = logistic_model(X_tn, X_tt, y_tn, y_tt)\n",
    "    trn_scores.append(trn)\n",
    "    tst_scores.append(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of our list of test scores is 0.5839675291730086\n",
      "The Standard Deviation of our list of test scores is 0.03335556621128024\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(f'The Mean of our list of test scores is {statistics.mean(tst_scores)}')\n",
    "print(f'The Standard Deviation of our list of test scores is {statistics.stdev(tst_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
