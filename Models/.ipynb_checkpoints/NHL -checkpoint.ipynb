{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV containing player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>PTS</th>\n",
       "      <th>+/-</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>SHFT</th>\n",
       "      <th>SHFT/G</th>\n",
       "      <th>PROD</th>\n",
       "      <th>POS</th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>TIMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Suter Ryan</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>-8</td>\n",
       "      <td>26:42:00</td>\n",
       "      <td>2222</td>\n",
       "      <td>27.1</td>\n",
       "      <td>46:34:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Doughty Drew</td>\n",
       "      <td>LA</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-34</td>\n",
       "      <td>26:36:00</td>\n",
       "      <td>2393</td>\n",
       "      <td>29.2</td>\n",
       "      <td>48:27:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Letang Kris</td>\n",
       "      <td>PIT</td>\n",
       "      <td>65.0</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>25:58:00</td>\n",
       "      <td>1923</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30:07:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jones Seth</td>\n",
       "      <td>CBJ</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>25:49:00</td>\n",
       "      <td>2214</td>\n",
       "      <td>29.5</td>\n",
       "      <td>42:06:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Josi Roman</td>\n",
       "      <td>NSH</td>\n",
       "      <td>82.0</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>25:10:00</td>\n",
       "      <td>2359</td>\n",
       "      <td>28.8</td>\n",
       "      <td>36:51:00</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        PLAYER TEAM    GP   G   A  PTS  +/-     TOI/G  SHFT  \\\n",
       "0           0    Suter Ryan  MIN  82.0   7  40   47   -8  26:42:00  2222   \n",
       "1           1  Doughty Drew   LA  82.0   8  37   45  -34  26:36:00  2393   \n",
       "2           2   Letang Kris  PIT  65.0  16  40   56   13  25:58:00  1923   \n",
       "3           3    Jones Seth  CBJ  75.0   9  37   46    1  25:49:00  2214   \n",
       "4           4    Josi Roman  NSH  82.0  15  41   56    9  25:10:00  2359   \n",
       "\n",
       "   SHFT/G      PROD POS    hr   min  sec   TIMES  \n",
       "0    27.1  46:34:00   D  26.0  42.0  0.0  2132.0  \n",
       "1    29.2  48:27:00   D  26.0  36.0  0.0  2132.0  \n",
       "2    29.6  30:07:00   D  25.0  58.0  0.0  1625.0  \n",
       "3    29.5  42:06:00   D  25.0  49.0  0.0  1875.0  \n",
       "4    28.8  36:51:00   D  25.0  10.0  0.0  2050.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOI_df = pd.read_csv('Final-DataFrames/NHLTotTime.csv')\n",
    "TOI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert \"Time On Ice per Game\" column to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>GP</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>PTS</th>\n",
       "      <th>+/-</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>SHFT</th>\n",
       "      <th>SHFT/G</th>\n",
       "      <th>PROD</th>\n",
       "      <th>POS</th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>TIMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Suter Ryan</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>-8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2222</td>\n",
       "      <td>27.1</td>\n",
       "      <td>46:34:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Doughty Drew</td>\n",
       "      <td>LA</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-34</td>\n",
       "      <td>26.6</td>\n",
       "      <td>2393</td>\n",
       "      <td>29.2</td>\n",
       "      <td>48:27:00</td>\n",
       "      <td>D</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        PLAYER TEAM    GP  G   A  PTS  +/- TOI/G  SHFT  SHFT/G  \\\n",
       "0           0    Suter Ryan  MIN  82.0  7  40   47   -8  26.7  2222    27.1   \n",
       "1           1  Doughty Drew   LA  82.0  8  37   45  -34  26.6  2393    29.2   \n",
       "\n",
       "       PROD POS    hr   min  sec   TIMES  \n",
       "0  46:34:00   D  26.0  42.0  0.0  2132.0  \n",
       "1  48:27:00   D  26.0  36.0  0.0  2132.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the times in the \"TOI/G\" column\n",
    "timelist = list(TOI_df['TOI/G'])\n",
    "\n",
    "for i in range(len(TOI_df['TOI/G'])):\n",
    "    timesplit = timelist[i].split(':')\n",
    "    \n",
    "    \n",
    "    whole = int(timesplit[0])\n",
    "    decimal = int(timesplit[1])/60\n",
    "    \n",
    "    minutes = whole + decimal\n",
    "    \n",
    "    TOI_df['TOI/G'][i] = minutes\n",
    "    \n",
    "TOI_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new DataFrame with important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHL_stats = TOI_df[['PLAYER', 'GP', 'TOI/G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read our CSV containing Bio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Injury Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32</td>\n",
       "      <td>Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25</td>\n",
       "      <td>Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21</td>\n",
       "      <td>Not Injured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27</td>\n",
       "      <td>Not Injured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 POSITION  HEIGHT  WEIGHT             PLAYER  AGE Injury Status\n",
       "0           0       LW    74.0     214  Abdelkader Justin   32       Injured\n",
       "1           1       LW    71.0     196       Aberg Pontus   25       Injured\n",
       "2           2       RW    69.0     171     Abramov Vitaly   21   Not Injured\n",
       "3           3        C    70.0     205       Acciari Noel   27   Not Injured"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Final-DataFrames/NHLModel.csv').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHL_1 = pd.read_csv('Final-DataFrames/NHLModel.csv')\n",
    "\n",
    "\n",
    "# Select columns of interest\n",
    "NHL_select = NHL_1[['POSITION', 'HEIGHT', 'WEIGHT', 'PLAYER', 'AGE', 'Injury Status']]\n",
    "\n",
    "#Merge Playerr Bio data with the player stat data \n",
    "NHL = NHL_select.merge(NHL_stats, how='right', on='PLAYER')\n",
    "\n",
    "#Drop NA rows\n",
    "NHL = NHL.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BMI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Injury Status</th>\n",
       "      <th>GP</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Injured</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>27.472973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Injured</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>27.333466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.8667</td>\n",
       "      <td>25.249527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.9833</td>\n",
       "      <td>29.411224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LW</td>\n",
       "      <td>72.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>Agostino Kenny</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Not Injured</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.9167</td>\n",
       "      <td>26.986304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POSITION  HEIGHT  WEIGHT             PLAYER   AGE Injury Status    GP  \\\n",
       "0       LW    74.0   214.0  Abdelkader Justin  32.0       Injured  71.0   \n",
       "1       LW    71.0   196.0       Aberg Pontus  25.0       Injured  59.0   \n",
       "2       RW    69.0   171.0     Abramov Vitaly  21.0   Not Injured   1.0   \n",
       "3        C    70.0   205.0       Acciari Noel  27.0   Not Injured  72.0   \n",
       "4       LW    72.0   199.0     Agostino Kenny  27.0   Not Injured  63.0   \n",
       "\n",
       "     TOI/G        BMI  \n",
       "0     15.4  27.472973  \n",
       "1     14.6  27.333466  \n",
       "2  13.8667  25.249527  \n",
       "3  12.9833  29.411224  \n",
       "4  12.9167  26.986304  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NHL['BMI'] = (NHL['WEIGHT'] / (NHL['HEIGHT'] ** 2)) * 703\n",
    "NHL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot Encode The NHL dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GP</th>\n",
       "      <th>TOI/G</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Injury Status_Injured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LW</td>\n",
       "      <td>74.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Abdelkader Justin</td>\n",
       "      <td>32.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>27.472973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LW</td>\n",
       "      <td>71.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Aberg Pontus</td>\n",
       "      <td>25.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>27.333466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RW</td>\n",
       "      <td>69.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Abramov Vitaly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.8667</td>\n",
       "      <td>25.249527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>70.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Acciari Noel</td>\n",
       "      <td>27.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.9833</td>\n",
       "      <td>29.411224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LW</td>\n",
       "      <td>72.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>Agostino Kenny</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.9167</td>\n",
       "      <td>26.986304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POSITION  HEIGHT  WEIGHT             PLAYER   AGE    GP    TOI/G        BMI  \\\n",
       "0       LW    74.0   214.0  Abdelkader Justin  32.0  71.0     15.4  27.472973   \n",
       "1       LW    71.0   196.0       Aberg Pontus  25.0  59.0     14.6  27.333466   \n",
       "2       RW    69.0   171.0     Abramov Vitaly  21.0   1.0  13.8667  25.249527   \n",
       "3        C    70.0   205.0       Acciari Noel  27.0  72.0  12.9833  29.411224   \n",
       "4       LW    72.0   199.0     Agostino Kenny  27.0  63.0  12.9167  26.986304   \n",
       "\n",
       "   Injury Status_Injured  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 = injured\n",
    "# 0 = not injured\n",
    "Encoded_df = pd.get_dummies(NHL, columns=['Injury Status'])[['POSITION', 'HEIGHT', 'WEIGHT', 'PLAYER', 'AGE', 'GP', 'TOI/G','BMI', 'Injury Status_Injured']]\n",
    "Encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set y values equal to our Injury Status_Injured column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(Encoded_df['Injury Status_Injured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = pd.get_dummies(Encoded_df[['POSITION', 'HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']], columns=['POSITION'])\n",
    "X = Encoded_df[['HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']]\n",
    "\n",
    "New_X = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(New_X, y, train_size=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([X_test[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6286149162861492\n",
      "Testing Data Score: 0.6073059360730594\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a StandardScater model and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train.reshape(-1, 1))\n",
    "# X_scaler = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform the training and testing data using the X_scaler and y_scaler models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.685\n",
      "k: 3, Train/Test Score: 0.854/0.712\n",
      "k: 5, Train/Test Score: 0.830/0.749\n",
      "k: 7, Train/Test Score: 0.813/0.749\n",
      "k: 9, Train/Test Score: 0.807/0.767\n",
      "k: 11, Train/Test Score: 0.799/0.740\n",
      "k: 13, Train/Test Score: 0.791/0.753\n",
      "k: 15, Train/Test Score: 0.793/0.763\n",
      "k: 17, Train/Test Score: 0.788/0.763\n",
      "k: 19, Train/Test Score: 0.790/0.763\n",
      "k: 21, Train/Test Score: 0.782/0.763\n",
      "k: 23, Train/Test Score: 0.781/0.753\n",
      "k: 25, Train/Test Score: 0.779/0.749\n",
      "k: 27, Train/Test Score: 0.778/0.749\n",
      "k: 29, Train/Test Score: 0.781/0.758\n",
      "k: 31, Train/Test Score: 0.775/0.744\n",
      "k: 33, Train/Test Score: 0.773/0.767\n",
      "k: 35, Train/Test Score: 0.766/0.781\n",
      "k: 37, Train/Test Score: 0.763/0.776\n",
      "k: 39, Train/Test Score: 0.763/0.776\n",
      "k: 41, Train/Test Score: 0.760/0.781\n",
      "k: 43, Train/Test Score: 0.760/0.781\n",
      "k: 45, Train/Test Score: 0.763/0.772\n",
      "k: 47, Train/Test Score: 0.761/0.776\n",
      "k: 49, Train/Test Score: 0.763/0.776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 50, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 50, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 50, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 25, Train/Test Score: 0.791/0.763\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "k = int( math.sqrt(len(X_train)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=16)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "train_score = knn.score(X_train_scaled, y_train)\n",
    "test_score = knn.score(X_test_scaled, y_test)\n",
    "train_scores.append(train_score)\n",
    "test_scores.append(test_score)\n",
    "print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions Based On X_Test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107,  21],\n",
       "       [ 51,  40]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712328767123288"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make random forest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict injury or no injury using clf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "#Here we run on the test set\n",
    "preds=clf.predict(X_test)\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print summary information from running prediction on X_test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted as injured:\n",
      "(100, 7)\n",
      "Predicted as not injured\n",
      "(119, 7)\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.DataFrame(X_test)\n",
    "newdf['predicted']=preds\n",
    "#print(newdf['predicted'].value_counts)\n",
    "#newdf.index\n",
    "#newdf.head()\n",
    "odf=Encoded_df.loc[newdf.index]\n",
    "odf['predicted']=preds\n",
    "print(\"Predicted as injured:\")\n",
    "print(newdf.loc[newdf.predicted==1].shape)\n",
    "print(\"Predicted as not injured\")\n",
    "print(newdf.loc[newdf.predicted==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9939117199391172\n",
      "Testing Data Score: 0.7488584474885844\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5205\n"
     ]
    }
   ],
   "source": [
    "# Assess quality of preditor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(odf['Injury Status_Injured'], odf['predicted']) \n",
    "print(\"MSE: %.4f\"%mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Our Model Functions From Our Python File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import train_test, logistic_model, knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Variables Based On The DataFrame and Columns of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['HEIGHT', 'WEIGHT', 'AGE', 'GP', 'TOI/G','BMI']\n",
    "X_tn, X_tt, y_tn, y_tt = train_test(Encoded_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6286149162861492\n",
      "Testing Data Score: 0.5799086757990868\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6362252663622526\n",
      "Testing Data Score: 0.589041095890411\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0\n",
      " 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0\n",
      " 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6133942161339422\n",
      "Testing Data Score: 0.5799086757990868\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.5981735159817352\n",
      "Testing Data Score: 0.5844748858447488\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0\n",
      " 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6225266362252664\n",
      "Testing Data Score: 0.5662100456621004\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6103500761035008\n",
      "Testing Data Score: 0.5616438356164384\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
      " 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.6103500761035008\n",
      "Testing Data Score: 0.6073059360730594\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      "---------------------------------\n",
      "Training Data Score: 0.604261796042618\n",
      "Testing Data Score: 0.6164383561643836\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "---------------------------------\n",
      "X_test Prediction: \n",
      "---------------------------------\n",
      "[1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1]\n",
      "---------------------------------\n",
      "Training Data Score: 0.578386605783866\n",
      "Testing Data Score: 0.6529680365296804\n"
     ]
    }
   ],
   "source": [
    "trn_scores = []\n",
    "tst_scores = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    X_tn, X_tt, y_tn, y_tt = train_test(Encoded_df, columns)\n",
    "    trn, tst = logistic_model(X_tn, X_tt, y_tn, y_tt)\n",
    "    trn_scores.append(trn)\n",
    "    tst_scores.append(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of our list of test scores is 0.5930999492643328\n",
      "The Standard Deviation of our list of test scores is 0.028465151003447563\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(f'The Mean of our list of test scores is {statistics.mean(tst_scores)}')\n",
    "print(f'The Standard Deviation of our list of test scores is {statistics.stdev(tst_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
